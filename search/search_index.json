{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Version control for software 2.0 Introduction Stockroom is a platform to version models, data, parameters, experiment artifacts etc. alongside git versioned source code. It is easy . The APIs are very similar to dictionaries in python It works alongside Git - in case you need to version source code as well. It's OK if you don't. High performance , thanks to the amazing hangar library Integration with PyTorch and its ecosystem, so that you don't need to write the complex pipeline code. Why One important motivation behind the initial design of stockroom is to avoid users learning another tool for versioning. We try to make the APIs as minimal and familiar as possible. Similar to other versioning tools, stockroom let \"git\" does checkout and rely on \"git\" to move between branches/commits. But unlike other tools, we channel your data access through the smart API so that we don't need to move the huge data files around when you traverse between commits. Installation $ pip install stockroom ---> 100% Example from stockroom import StockRoom stock = StockRoom ( enable_write = True ) model . load_state_dict ( stock . model [ 'resnet50' ]) for e in range ( epochs ): for i in range ( limit ): optimizer . zero_grad () x , y = stock . data [ 'dataset_name' , i ] out = model ( x ) loss = criterion ( out , y ) loss . backward () optimizer . step () if loss < previous_loss : stock . experiment [ 'loss' ] = loss . item () stock . model [ 'resnet50' ] = model . state_dict () stock . commit ( 'adding a better model' ) Contributing We'd love to have you in the contributors list. Do check out the contribution guide before submitting a PR. Here is our latest #Hall-Of-Fame License This project is licensed under the terms of the Apache Software License 2.0","title":"Home"},{"location":"#introduction","text":"Stockroom is a platform to version models, data, parameters, experiment artifacts etc. alongside git versioned source code. It is easy . The APIs are very similar to dictionaries in python It works alongside Git - in case you need to version source code as well. It's OK if you don't. High performance , thanks to the amazing hangar library Integration with PyTorch and its ecosystem, so that you don't need to write the complex pipeline code.","title":"Introduction"},{"location":"#why","text":"One important motivation behind the initial design of stockroom is to avoid users learning another tool for versioning. We try to make the APIs as minimal and familiar as possible. Similar to other versioning tools, stockroom let \"git\" does checkout and rely on \"git\" to move between branches/commits. But unlike other tools, we channel your data access through the smart API so that we don't need to move the huge data files around when you traverse between commits.","title":"Why"},{"location":"#installation","text":"$ pip install stockroom ---> 100%","title":"Installation"},{"location":"#example","text":"from stockroom import StockRoom stock = StockRoom ( enable_write = True ) model . load_state_dict ( stock . model [ 'resnet50' ]) for e in range ( epochs ): for i in range ( limit ): optimizer . zero_grad () x , y = stock . data [ 'dataset_name' , i ] out = model ( x ) loss = criterion ( out , y ) loss . backward () optimizer . step () if loss < previous_loss : stock . experiment [ 'loss' ] = loss . item () stock . model [ 'resnet50' ] = model . state_dict () stock . commit ( 'adding a better model' )","title":"Example"},{"location":"#contributing","text":"We'd love to have you in the contributors list. Do check out the contribution guide before submitting a PR. Here is our latest #Hall-Of-Fame","title":"Contributing"},{"location":"#license","text":"This project is licensed under the terms of the Apache Software License 2.0","title":"License"},{"location":"changelog/","text":"Changelog All notable changes to this project will be documented here The format is a modified version based on Keep a Changelog , and this project adheres to Semantic Versioning In Progress [ Added ] VOC segmentation dataset from torchvision. #39 @jjmachan [ Added ] Read only stock objects can right inside enable_write context manager. #37 @hhsecond [ Breaking change ] stock.run() is removed. All the write enabled accessors optimized on creation #37 @hhsecond [ Breaking change ] .keys() returns relevant keys. This change breaks the model storage APIs #35 @hhsecond [ Added ] Rich powered console messages #32 @jjmachan [ Fixed ] Structural change and shape error fix in import utility #27 @jjmachan 0.2.2 2020-08-06 [ Fixed ] Import error on make_torch_dataset with hangar's old version #26 @hhsecond 0.2.1 2020-08-06 [ Added ] The import CLI for importing PyTorch datasets (torchvision, torchtext and torchaudio) #17 @jjmachan [ Changed ] Hangar's new column API #12 @hhsecond [ Changed ] Global read optimization #11 @hhsecond [ Changed ] Singleton for holding the checkout object has been removed #3 @hhsecond 0.1.0 2019-12-12 First release on PyPI","title":"Release Notes"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented here The format is a modified version based on Keep a Changelog , and this project adheres to Semantic Versioning","title":"Changelog"},{"location":"changelog/#in-progress","text":"[ Added ] VOC segmentation dataset from torchvision. #39 @jjmachan [ Added ] Read only stock objects can right inside enable_write context manager. #37 @hhsecond [ Breaking change ] stock.run() is removed. All the write enabled accessors optimized on creation #37 @hhsecond [ Breaking change ] .keys() returns relevant keys. This change breaks the model storage APIs #35 @hhsecond [ Added ] Rich powered console messages #32 @jjmachan [ Fixed ] Structural change and shape error fix in import utility #27 @jjmachan","title":"In Progress"},{"location":"changelog/#022","text":"2020-08-06 [ Fixed ] Import error on make_torch_dataset with hangar's old version #26 @hhsecond","title":"0.2.2"},{"location":"changelog/#021","text":"2020-08-06 [ Added ] The import CLI for importing PyTorch datasets (torchvision, torchtext and torchaudio) #17 @jjmachan [ Changed ] Hangar's new column API #12 @hhsecond [ Changed ] Global read optimization #11 @hhsecond [ Changed ] Singleton for holding the checkout object has been removed #3 @hhsecond","title":"0.2.1"},{"location":"changelog/#010","text":"2019-12-12 First release on PyPI","title":"0.1.0"},{"location":"cli/","text":"CLI Reference This page provides documentation for our command line tools. stock The stock CLI provides a git-like experience (whenever possible) to interact with the stock repository. It also means that the current working directory is where the stock repository would exist (like git \ud83d\ude0a ). Usage: stock [OPTIONS] COMMAND [ARGS]... Options: --version display current stockroom version commit It does a stock commit. Stock commit consists of two actions Make a hangar commit Update the head.stock file (git will track this file if you are using git) Usage: stock commit [OPTIONS] Options: -m, --message TEXT The commit message. If multiple arguments are provided, each of them gets converted into a new line import Downloads and add a pytorch dataset (from torchvision, torchtext or torchaudio) to StockRoom. It creates the repo if it doesn't exist and loads the dataset into a repo for you Usage: stock import [OPTIONS] DATASET_NAME Options: -d, --download-dir PATH If you have the dataset downloaded in a non-default path or want to download it to a non-default path, pass it here init Init stockroom repository. This will create a .hangar directory and a head.stock file in your cwd . stock init would be triggered implicitly if you are making a stock repository by using stock import but in all other case, you'd need to initialize a stock repository to start operating on it with the python APIs Usage: stock init [OPTIONS] Options: --username TEXT Username of the user --email TEXT Email address of the user --overwrite overwrite a repository if it exists at the current path liberate Release the writer lock forcefully and make the repository available for writing. Warning If another process, that has the writer lock, is writing to the repo, releasing the lock leads to an exception in that process. Use it carefully Usage: stock liberate [OPTIONS]","title":"CLI Reference"},{"location":"cli/#cli-reference","text":"This page provides documentation for our command line tools.","title":"CLI Reference"},{"location":"cli/#stock","text":"The stock CLI provides a git-like experience (whenever possible) to interact with the stock repository. It also means that the current working directory is where the stock repository would exist (like git \ud83d\ude0a ). Usage: stock [OPTIONS] COMMAND [ARGS]... Options: --version display current stockroom version","title":"stock"},{"location":"cli/#commit","text":"It does a stock commit. Stock commit consists of two actions Make a hangar commit Update the head.stock file (git will track this file if you are using git) Usage: stock commit [OPTIONS] Options: -m, --message TEXT The commit message. If multiple arguments are provided, each of them gets converted into a new line","title":"commit"},{"location":"cli/#import","text":"Downloads and add a pytorch dataset (from torchvision, torchtext or torchaudio) to StockRoom. It creates the repo if it doesn't exist and loads the dataset into a repo for you Usage: stock import [OPTIONS] DATASET_NAME Options: -d, --download-dir PATH If you have the dataset downloaded in a non-default path or want to download it to a non-default path, pass it here","title":"import"},{"location":"cli/#init","text":"Init stockroom repository. This will create a .hangar directory and a head.stock file in your cwd . stock init would be triggered implicitly if you are making a stock repository by using stock import but in all other case, you'd need to initialize a stock repository to start operating on it with the python APIs Usage: stock init [OPTIONS] Options: --username TEXT Username of the user --email TEXT Email address of the user --overwrite overwrite a repository if it exists at the current path","title":"init"},{"location":"cli/#liberate","text":"Release the writer lock forcefully and make the repository available for writing.","title":"liberate"},{"location":"cli/#warning","text":"If another process, that has the writer lock, is writing to the repo, releasing the lock leads to an exception in that process. Use it carefully Usage: stock liberate [OPTIONS]","title":"Warning"},{"location":"cli/#_1","text":"","title":""},{"location":"contributing/","text":"If you wish to contribute to stockroom (yaay!!\ud83c\udf89\ud83c\udf89) decide whether it needs to be discussed with the dev team before you start spending time on it. If you are in doubt, ask us in slack or raise a Github issue (\ud83d\ude44) You'd need to fork the stockroom repository (look for the \"Fork\" button on top right) and then clone the fork locally. git clone git@github.com:your_name_here/stockroom.git Create a branch locally and make your changes. Feel free to reach us if you need a code review before you finish your work git checkout -b your-branch-name Contributing to the code Once done with the changes, run the test suite. It will run existing test cases, check coverage, run black and mypy . Also, make sure you have updated the documentation, added required test cases and modified the changelog.md file in docs directory before creating the PR $ bash ./scripts/test.sh ---> 100% Contributing to the documentation We are using the amazing mkdocs library for documentation. You can spin up the mkdocs live debugging server from the root of the repository and see the changes you are making in realtime. $ mkdocs serve ---> 100%","title":"Contribution Guide"},{"location":"contributing/#contributing-to-the-code","text":"Once done with the changes, run the test suite. It will run existing test cases, check coverage, run black and mypy . Also, make sure you have updated the documentation, added required test cases and modified the changelog.md file in docs directory before creating the PR $ bash ./scripts/test.sh ---> 100%","title":"Contributing to the code"},{"location":"contributing/#contributing-to-the-documentation","text":"We are using the amazing mkdocs library for documentation. You can spin up the mkdocs live debugging server from the root of the repository and see the changes you are making in realtime. $ mkdocs serve ---> 100%","title":"Contributing to the documentation"},{"location":"help-us/","text":"Stockroom is still in its early stages and we are grateful to you for being part of the stockroom-hangar community. If you love stockroom and if you wish to help us, there are few ways you can contribute. Contributing in the design discussions, writing code and sending PR are extremely impactful at this early times but there are other simpler ways as well. Give us a star at Github \u2b50\ufe0f\ufe0f in Github let people know that stockroom is useful for others already and it will give us confidence that we are heading in the right direction. You can find our Github page here Be part of the slack community We have a #stockroom channel in HangarUserGroup slack. Feel free to chime in, ask questions if you have. It would also helpful if you can hang around and help the community there. Take part in our weekly design calls We run weekly design calls for around Hangar and Stockroom, mostly on Tuesdays. Hop in if you could spare 30 minutes. We'll announce the topic and time every week through our twitter . Recordings of our past sessions are available here Feedback Give us your feedback!! If you love stockroom, let us know what in stockroom you are fond of particularly. If you hate it, we'd like to know how can we make it better. Slack is the best platform to reach us for feedback at this point in time but feel free to talk to us through twitter or even over email . If you find a bug or you have a specific question you'd want one of the core devs to answer, choose the proper label while you create an issue Feature request If you have a feature in mind that you think would fit in stockroom well, choose \"Feature Request\" in the Github issue page and create an issue Pull request Contributing to the repository is invaluable for us and the community right now. If you'd like to build a new feature or fix an existing bug, please do raise an issue first. It might be the case that the feature you are trying to build is already built and under testing, or it might contradict the design ideas we have kept intact. Discussing it first would save our time. If you find a typo in the documentation or if you'd like to do small fixes or clean up, feel free to raise a PR without raising an issue. Tweet about us Let the world know how you have used stockroom. Use the hashtag #stockroom or tag our handle @tensorwerk . We are listening.","title":"Help Us"},{"location":"help-us/#give-us-a-star-at-github","text":"\u2b50\ufe0f\ufe0f in Github let people know that stockroom is useful for others already and it will give us confidence that we are heading in the right direction. You can find our Github page here","title":"Give us a star at Github"},{"location":"help-us/#be-part-of-the-slack-community","text":"We have a #stockroom channel in HangarUserGroup slack. Feel free to chime in, ask questions if you have. It would also helpful if you can hang around and help the community there.","title":"Be part of the slack community"},{"location":"help-us/#take-part-in-our-weekly-design-calls","text":"We run weekly design calls for around Hangar and Stockroom, mostly on Tuesdays. Hop in if you could spare 30 minutes. We'll announce the topic and time every week through our twitter . Recordings of our past sessions are available here","title":"Take part in our weekly design calls"},{"location":"help-us/#feedback","text":"Give us your feedback!! If you love stockroom, let us know what in stockroom you are fond of particularly. If you hate it, we'd like to know how can we make it better. Slack is the best platform to reach us for feedback at this point in time but feel free to talk to us through twitter or even over email . If you find a bug or you have a specific question you'd want one of the core devs to answer, choose the proper label while you create an issue","title":"Feedback"},{"location":"help-us/#feature-request","text":"If you have a feature in mind that you think would fit in stockroom well, choose \"Feature Request\" in the Github issue page and create an issue","title":"Feature request"},{"location":"help-us/#pull-request","text":"Contributing to the repository is invaluable for us and the community right now. If you'd like to build a new feature or fix an existing bug, please do raise an issue first. It might be the case that the feature you are trying to build is already built and under testing, or it might contradict the design ideas we have kept intact. Discussing it first would save our time. If you find a typo in the documentation or if you'd like to do small fixes or clean up, feel free to raise a PR without raising an issue.","title":"Pull request"},{"location":"help-us/#tweet-about-us","text":"Let the world know how you have used stockroom. Use the hashtag #stockroom or tag our handle @tensorwerk . We are listening.","title":"Tweet about us"},{"location":"quick-start/","text":"\ud83c\udfc3\u200d\u2640\ufe0f Quick Start Eager to take a quick run through stockroom? This page gives a good and crisp introduction to stockroom. Import a cifar10 dataset from torchvision to stockroom Train a CNN with this data Save the hyper parameters and model to stockroom for reproducibility You need to install stockroom , pytorch , torchvision and matplotlib for this tutorial Use conda installing pytorch and torchvision using pypi might install the manylinux bundle which is huge in size. Use conda if you can Introduction Stockroom exposes the environment as three shelves. Data, Model and Experiments. This segregation let stockroom to be prejudice about what goes inside and optimize the storage. Stockroom also introduces stock CLI which gives you the ability to interact with your stockroom repository in a git-like way. Checkout the reference doc for complete CLI reference. You'll be using both the CLI and Python APIs of stockroom in this tutorial. Initialize Stock Repository CD to your project directory and initialize it as a stock repository $ stock init --username myname --email a@b.c ---> 100% Import CIFAR10 StockRoom keeps all your data in .data shelf arranged as columns. In our case, data is imported as four columns. Train images Train labels Test images Test labels Data is Tensor Stockroom makes strong assumptions about your data. Any data point that goes into stockroom must be a tensor a.k.a numpy.ndarray object. It is why stockroom could optimize the data storage and versioning efficiently. Also, know that, this philosophy is originally from Hangar and we use Hangar internally for all type of storages $ stock import torchvision.cifar10 Downloading cifar-10-python.tar.gz ---> 100% Adding cifar10 dataset to StockRoom ---> 100% Done! Once you have the CIFAR data downloaded and added to your stock repository, you can create your project files and start building the network. We are using the CIFAR10 example from pytorch's blitz tutorial here, with few modification to load the data from stockroom instead of torchvision. Stockroom is better off with git Stockroom is designed to be able work without git but git will enable you to track your source code along with machine learning artifacts and data Build The Model We'll build a simple CNN model as given in the pytorch tutorial import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x Exploring data Stockroom gives you simple, dictionary-like APIs for accessing and storing things. You'd create a stock object that gives you the access to the storage from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Read Access Making stock object as given above will only give you a read enabled object. For saving data, you'd need to open the enable_write context manager or create the stock object by enabling write mode. stock = StockRoom () with stock . enable_write (): write_into ( stock ) # or stock = StockRoom ( enable_write = True ) write_into ( stock ) You'll see an example below Accessing data As you already know, data is stored as columns inside the .data shelf in stockroom. You can get fetch the column from the .data attribute and then fetch the data at a particular index - here we take the 100th data point. from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Column Names You need to know the column names to interact with the data in the .data shelf. These names will be printed to the terminal when you import data. But if you missed/forget them, use stock . data . keys () DataLoader Making a PyTorch DataLoader for your data is possible with the make_torch_dataset function. It takes columns as first argument in a python list/tuple and gives you the element from each column on a particular index Info make_torch_dataset is a Hangar function and stockroom only exposing it for convenience Make Dataset from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 ) Make DataLoader The dataset returned from make_torch_dataset is a subclass of torch.utils.data.Dataset and hence is understood by torch DataLoader . You could create the dataloader as you create with any dataset. Huge batch size, custom collate function, multiple threads - doesn't matter. Use it as you wish. Remember, you have made a read only stock object, you'd never corrupt your data with that. from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 ) Training We'll open a write enabled stock object here since we need to store experiment information (hyper parameters, metrics, output, artifacts etc) and model to stockroom. Careful with the write access With more power comes more responsibility. Remember, you can write to your repository Your data is safe With the power of hangar, any data that is committed to stockroom is safe there. Even if you overwrite that data in a new commit, you can always time travel to previous commit and access your old data Store hyper-parameters As .data shelf store your data, hyper-parameters and experiment artifacts must be stored in the .experiment shelf. While the .data shelf only allow you to store tensor data, .experiment shelf will eventually allow you to store any artificats, like a loss graph, or a pickled file you'd need for training your model etc. for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : with stock . enable_write ( commit_msg = f \" { best_loss =} \" ): stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () best_loss = current_loss Store model The .model shelf takes state_dict from a pytorch model and nothing else. You will eventually be able to store a jit ed model into your .experiment store but .model shelf is designed to store your model weights passed as a dictionary. for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : with stock . enable_write ( commit_msg = f \" { best_loss =} \" ): stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () best_loss = current_loss Storing weights is better As far as you version your source code, saving the weights is always better. We are building more utilities, especially visualization tools, to interact with the data in stockroom. This will eventually help you to analyze the model weights, visualize them and even diff it \ud83e\udd2f\ud83d\ude0d Commit your changes Commit your changes as you move forward, you can always time travel back and look at. With the context managers, autocommit is enabled by default. You can control this behaviour by changing the argument value .data or .experiment or .model shelves for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : with stock . enable_write ( commit_msg = f \" { best_loss =} \" ): stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () best_loss = current_loss stock commit != git commit Stock commit is not same as a git commit. In fact, you can combine multiple stock commit in one git commit and consider that as an experiment Recap Initialize stock repository Import torchvision dataset to the repository Build the network Train your network Add data, augment it, experiment with hyper parameters but commit to stockroom along with you commit your source code In case you need, the source code for the above experiment is available at the github repository hhsecond/stockroom-cifar10","title":"Quick Start"},{"location":"quick-start/#quick-start","text":"Eager to take a quick run through stockroom? This page gives a good and crisp introduction to stockroom. Import a cifar10 dataset from torchvision to stockroom Train a CNN with this data Save the hyper parameters and model to stockroom for reproducibility You need to install stockroom , pytorch , torchvision and matplotlib for this tutorial Use conda installing pytorch and torchvision using pypi might install the manylinux bundle which is huge in size. Use conda if you can","title":"\ud83c\udfc3\u200d\u2640\ufe0f Quick Start"},{"location":"quick-start/#introduction","text":"Stockroom exposes the environment as three shelves. Data, Model and Experiments. This segregation let stockroom to be prejudice about what goes inside and optimize the storage. Stockroom also introduces stock CLI which gives you the ability to interact with your stockroom repository in a git-like way. Checkout the reference doc for complete CLI reference. You'll be using both the CLI and Python APIs of stockroom in this tutorial.","title":"Introduction"},{"location":"quick-start/#initialize-stock-repository","text":"CD to your project directory and initialize it as a stock repository $ stock init --username myname --email a@b.c ---> 100%","title":"Initialize Stock Repository"},{"location":"quick-start/#import-cifar10","text":"StockRoom keeps all your data in .data shelf arranged as columns. In our case, data is imported as four columns. Train images Train labels Test images Test labels Data is Tensor Stockroom makes strong assumptions about your data. Any data point that goes into stockroom must be a tensor a.k.a numpy.ndarray object. It is why stockroom could optimize the data storage and versioning efficiently. Also, know that, this philosophy is originally from Hangar and we use Hangar internally for all type of storages $ stock import torchvision.cifar10 Downloading cifar-10-python.tar.gz ---> 100% Adding cifar10 dataset to StockRoom ---> 100% Done! Once you have the CIFAR data downloaded and added to your stock repository, you can create your project files and start building the network. We are using the CIFAR10 example from pytorch's blitz tutorial here, with few modification to load the data from stockroom instead of torchvision. Stockroom is better off with git Stockroom is designed to be able work without git but git will enable you to track your source code along with machine learning artifacts and data","title":"Import CIFAR10"},{"location":"quick-start/#build-the-model","text":"We'll build a simple CNN model as given in the pytorch tutorial import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x","title":"Build The Model"},{"location":"quick-start/#exploring-data","text":"Stockroom gives you simple, dictionary-like APIs for accessing and storing things. You'd create a stock object that gives you the access to the storage from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Read Access Making stock object as given above will only give you a read enabled object. For saving data, you'd need to open the enable_write context manager or create the stock object by enabling write mode. stock = StockRoom () with stock . enable_write (): write_into ( stock ) # or stock = StockRoom ( enable_write = True ) write_into ( stock ) You'll see an example below","title":"Exploring data"},{"location":"quick-start/#accessing-data","text":"As you already know, data is stored as columns inside the .data shelf in stockroom. You can get fetch the column from the .data attribute and then fetch the data at a particular index - here we take the 100th data point. from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Column Names You need to know the column names to interact with the data in the .data shelf. These names will be printed to the terminal when you import data. But if you missed/forget them, use stock . data . keys ()","title":"Accessing data"},{"location":"quick-start/#dataloader","text":"Making a PyTorch DataLoader for your data is possible with the make_torch_dataset function. It takes columns as first argument in a python list/tuple and gives you the element from each column on a particular index Info make_torch_dataset is a Hangar function and stockroom only exposing it for convenience","title":"DataLoader"},{"location":"quick-start/#make-dataset","text":"from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 )","title":"Make Dataset"},{"location":"quick-start/#make-dataloader","text":"The dataset returned from make_torch_dataset is a subclass of torch.utils.data.Dataset and hence is understood by torch DataLoader . You could create the dataloader as you create with any dataset. Huge batch size, custom collate function, multiple threads - doesn't matter. Use it as you wish. Remember, you have made a read only stock object, you'd never corrupt your data with that. from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 )","title":"Make DataLoader"},{"location":"quick-start/#training","text":"We'll open a write enabled stock object here since we need to store experiment information (hyper parameters, metrics, output, artifacts etc) and model to stockroom. Careful with the write access With more power comes more responsibility. Remember, you can write to your repository Your data is safe With the power of hangar, any data that is committed to stockroom is safe there. Even if you overwrite that data in a new commit, you can always time travel to previous commit and access your old data","title":"Training"},{"location":"quick-start/#store-hyper-parameters","text":"As .data shelf store your data, hyper-parameters and experiment artifacts must be stored in the .experiment shelf. While the .data shelf only allow you to store tensor data, .experiment shelf will eventually allow you to store any artificats, like a loss graph, or a pickled file you'd need for training your model etc. for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : with stock . enable_write ( commit_msg = f \" { best_loss =} \" ): stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () best_loss = current_loss","title":"Store hyper-parameters"},{"location":"quick-start/#store-model","text":"The .model shelf takes state_dict from a pytorch model and nothing else. You will eventually be able to store a jit ed model into your .experiment store but .model shelf is designed to store your model weights passed as a dictionary. for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : with stock . enable_write ( commit_msg = f \" { best_loss =} \" ): stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () best_loss = current_loss Storing weights is better As far as you version your source code, saving the weights is always better. We are building more utilities, especially visualization tools, to interact with the data in stockroom. This will eventually help you to analyze the model weights, visualize them and even diff it \ud83e\udd2f\ud83d\ude0d","title":"Store model"},{"location":"quick-start/#commit-your-changes","text":"Commit your changes as you move forward, you can always time travel back and look at. With the context managers, autocommit is enabled by default. You can control this behaviour by changing the argument value .data or .experiment or .model shelves for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : with stock . enable_write ( commit_msg = f \" { best_loss =} \" ): stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () best_loss = current_loss stock commit != git commit Stock commit is not same as a git commit. In fact, you can combine multiple stock commit in one git commit and consider that as an experiment","title":"Commit your changes"},{"location":"quick-start/#recap","text":"Initialize stock repository Import torchvision dataset to the repository Build the network Train your network Add data, augment it, experiment with hyper parameters but commit to stockroom along with you commit your source code In case you need, the source code for the above experiment is available at the github repository hhsecond/stockroom-cifar10","title":"Recap"}]}