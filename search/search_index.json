{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A version control system for software 2.0. Introduction Stockroom is a platform to version models, data, parameters, experiment artifacts etc. alongside git versioned source code. It is easy . The APIs are very similar to dictionaries in python It works alongside Git - in case you need to version source code as well. It's OK if you don't. High performance , thanks to the amazing hangar library Integration with PyTorch and it's ecosystem, so that you don't need to write the complex pipeline code. Why One important motivation behind the initial design of stockroom is to avoid users learning another tool for versioning. We try to make the APIs as minimal and familiar as possible. Similar to other versioning tools, stockroom let \"git\" does checkout and rely on \"git\" to move between branches/commits. But unlike other tools, we channel your data access through the smart API so that we don't need to move the huge data files around when you traverse between commits. Installation $ pip install stockroom ---> 100% Example from stockroom import StockRoom stock = StockRoom ( write = True ) model . load_state_dict ( stock . model [ 'resnet50' ]) for e in range ( epochs ): for i in range ( limit ): optimizer . zero_grad () x , y = stock . data [ 'dataset_name' , i ] out = model ( x ) loss = criterion ( out , y ) loss . backward () optimizer . step () if loss < previous_loss : stock . experiment [ 'loss' ] = loss . item () stock . model [ 'resnet50' ] = model . state_dict () stock . commit ( 'adding a better model' ) Contributing We'd love to have you in the contributors list. Do check out the contributor's guide before submitting a PR. Here is our latest #Hall-Of-Fame License This project is licensed under the terms of the Apache Software License 2.0","title":"Home"},{"location":"#introduction","text":"Stockroom is a platform to version models, data, parameters, experiment artifacts etc. alongside git versioned source code. It is easy . The APIs are very similar to dictionaries in python It works alongside Git - in case you need to version source code as well. It's OK if you don't. High performance , thanks to the amazing hangar library Integration with PyTorch and it's ecosystem, so that you don't need to write the complex pipeline code.","title":"Introduction"},{"location":"#why","text":"One important motivation behind the initial design of stockroom is to avoid users learning another tool for versioning. We try to make the APIs as minimal and familiar as possible. Similar to other versioning tools, stockroom let \"git\" does checkout and rely on \"git\" to move between branches/commits. But unlike other tools, we channel your data access through the smart API so that we don't need to move the huge data files around when you traverse between commits.","title":"Why"},{"location":"#installation","text":"$ pip install stockroom ---> 100%","title":"Installation"},{"location":"#example","text":"from stockroom import StockRoom stock = StockRoom ( write = True ) model . load_state_dict ( stock . model [ 'resnet50' ]) for e in range ( epochs ): for i in range ( limit ): optimizer . zero_grad () x , y = stock . data [ 'dataset_name' , i ] out = model ( x ) loss = criterion ( out , y ) loss . backward () optimizer . step () if loss < previous_loss : stock . experiment [ 'loss' ] = loss . item () stock . model [ 'resnet50' ] = model . state_dict () stock . commit ( 'adding a better model' )","title":"Example"},{"location":"#contributing","text":"We'd love to have you in the contributors list. Do check out the contributor's guide before submitting a PR. Here is our latest #Hall-Of-Fame","title":"Contributing"},{"location":"#license","text":"This project is licensed under the terms of the Apache Software License 2.0","title":"License"},{"location":"cli/","text":"CLI Reference This page provides documentation for our command line tools. stock The stock CLI provides a git-like experience (whenever possible) to interact with the stock repository. It also means that the current working directory is where the stock repository would exist (like git \ud83d\ude0a ). Usage: stock [OPTIONS] COMMAND [ARGS]... Options: --version display current stockroom version commit It does a stock commit. Stock commit consists of two actions Make a hangar commit Update the head.stock file (git will track this file if you are using git) Usage: stock commit [OPTIONS] Options: -m, --message TEXT The commit message. If multiple arguments are provided, each of them gets converted into a new line import Downloads and add a pytorch dataset (from torchvision, torchtext or torchaudio) to StockRoom. It creates the repo if it doesn't exist and loads the dataset into a repo for you Usage: stock import [OPTIONS] DATASET_NAME Options: -d, --download-dir PATH If you have the dataset downloaded in a non-default path or want to download it to a non-default path, pass it here init Init stockroom repository. This will create a .hangar directory and a head.stock file in your cwd . stock init would be triggered implicitly if you are making a stock repository by using stock import but in all other case, you'd need to initialize a stock repository to start operating on it with the python APIs Usage: stock init [OPTIONS] Options: --username TEXT Username of the user --email TEXT Email address of the user --overwrite overwrite a repository if it exists at the current path","title":"CLI Reference"},{"location":"cli/#cli-reference","text":"This page provides documentation for our command line tools.","title":"CLI Reference"},{"location":"cli/#stock","text":"The stock CLI provides a git-like experience (whenever possible) to interact with the stock repository. It also means that the current working directory is where the stock repository would exist (like git \ud83d\ude0a ). Usage: stock [OPTIONS] COMMAND [ARGS]... Options: --version display current stockroom version","title":"stock"},{"location":"cli/#commit","text":"It does a stock commit. Stock commit consists of two actions Make a hangar commit Update the head.stock file (git will track this file if you are using git) Usage: stock commit [OPTIONS] Options: -m, --message TEXT The commit message. If multiple arguments are provided, each of them gets converted into a new line","title":"commit"},{"location":"cli/#import","text":"Downloads and add a pytorch dataset (from torchvision, torchtext or torchaudio) to StockRoom. It creates the repo if it doesn't exist and loads the dataset into a repo for you Usage: stock import [OPTIONS] DATASET_NAME Options: -d, --download-dir PATH If you have the dataset downloaded in a non-default path or want to download it to a non-default path, pass it here","title":"import"},{"location":"cli/#init","text":"Init stockroom repository. This will create a .hangar directory and a head.stock file in your cwd . stock init would be triggered implicitly if you are making a stock repository by using stock import but in all other case, you'd need to initialize a stock repository to start operating on it with the python APIs Usage: stock init [OPTIONS] Options: --username TEXT Username of the user --email TEXT Email address of the user --overwrite overwrite a repository if it exists at the current path","title":"init"},{"location":"cli/#_1","text":"","title":""},{"location":"quick-start/","text":"\ud83c\udfc3\u200d\u2640\ufe0f Quick Start Eager to start using stockroom? This page gives a good and crisp introduction to stockroom. Import a cifar10 dataset from torchvision to stockroom Train a CNN with this data Save the hyper parameters and model to stockroom for reproducibility You need to install stockroom , pytorch , torchvision and matplotlib for this tutorial Use conda installing pytorch and torchvision using pypi might install the manylinux bundle which is huge in size. Use conda if you can Introduction Stockroom exposes the data as three shelves. Data, Model and Experiments. This segregation let stockroom to be prejudice about what goes inside and optimize the storage. Stockroom also introduces stock CLI which gives you the ability to interact with your stockroom repository in a git-like way. Checkout the reference doc for complete CLI reference. You'll be using both the CLI and Python APIs of stockroom in this tutorial. Initialize Stock Repository CD to your project directory and initialize it as a stock repository $ stock init --username myname --email a@b.c ---> 100% Import CIFAR10 StockRoom keeps all your data in .data shelf arranged as columns. In our case, data is imported as four columns. Train images Train labels Test images Test labels Data is Tensor Stockroom makes strong assumptions about your data. Any data point that goes into stockroom must be a tensor a.k.a numpy.ndarray object. It is why stockroom could optimize the data storage and versioning efficiently. Also, know that, we have borrowed this philosophy from Hangar $ stock import torchvision.cifar10 Downloading cifar-10-python.tar.gz ---> 100% Adding cifar10 dataset to StockRoom ---> 100% Done! Once you have the CIFAR data downloaded and added to your stock repository, you can create your project files and start building the network. We are using the CIFAR10 example from pytorch's blitz tutorial here, with few modification to load the data from stockroom instead of torchvision. Stockroom is better off with git Stockroom is designed to be able work without git but git will enable you to track your source code along with machine learning artifacts and data Build The Model We'll build a simple CNN model as given in the pytorch tutorial import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x Exploring data Stockroom gives you simple, dictionary-like APIs for accessing and storing things. You'd create a stock object that gives you the access to the storage from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Read Access Making stock object as given above will only give you a read enabled object. For saving data, you'd need to make a write enabled object using stock = StockRoom ( write = True ) You'll see an example below Accessing data As you already know, data is stored as columns inside the .data shelf in stockroom. You can get fetch the column from the .data attribute and then fetch the data at a particular index - here we take the 100th data point. from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Column Names You need to know the column names to interact with the data in the .data shelf. Use stock . data . keys () DataLoader Making a PyTorch DataLoader for your data is possible with the make_torch_dataset function. It takes columns as first argument in a python list/tuple and gives you the element from each column on a particular index Info make_torch_dataset is a Hangar function and stockroom only exposing it for convenience Make Dataset from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 ) Make DataLoader The dataset returned from make_torch_dataset is a subclass of torch.utils.data.Dataset and hence is understood by torch DataLoader . You could create the dataloader as you create with any dataset. Huge batch size, custom collate function, multiple threads - doesn't matter. Use it as you wish. Remember, you have made a read only stock object, you'd never corrupt your data with that. from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 ) Training We'll open a write enabled stock object here since we need to store experiment information (hyper parameters, metrics, output, artifacts etc) and model to stockroom. Careful with the write access With more power comes more responsibility. Remember, you can write to your repository Your data is safe With the power of hangar, any data that is committed to stockroom is safe there. Even if you overwrite that data in a new commit, you can always time travel to previous commit and access your old data Store hyper-parameters As .data shelf store your data, hyper-parameters and experiment artifacts must be stored in the .experiment shelf. While the .data shelf only allow you to store tensor data, .experiment shelf will eventually allow you to store any artificats, like a loss graph, or a pickled file you'd need for training your model etc. stock = StockRoom ( write = True ) for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () stock . commit ( f \"Experiment with better result. Loss= { best_loss } \" ) best_loss = current_loss Store model The .model shelf takes state_dict from a pytorch model and nothing else. You will eventually be able to store a jit ed model into your .experiment store but .model shelf is designed to store your model weights passed as a dictionary. stock = StockRoom ( write = True ) for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () stock . commit ( f \"Experiment with better result. Loss= { best_loss } \" ) best_loss = current_loss Storing weights is better As far as you version your source code, saving the weights is always better. We are building more utilities, especially visualization tools, to interact with the data in stockroom. This will eventually help you to analyze the model weights, visualize them and even diff it \ud83e\udd2f\ud83d\ude0d Commit your changes Commit your changes as you move forward, you can always time travel back and look at .data or .experiment or .model shelves stock = StockRoom ( write = True ) for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () stock . commit ( f \"Experiment with better result. Loss= { best_loss } \" ) best_loss = current_loss stock commit != git commit Stock commit is not same as a git commit. In fact, you can combine multiple stock commit in one git commit and consider that as an experiment Recap Initialize stock repository Import torchvision dataset to the repository Build the network Train your network Add data, augment it, experiment with hyper parameters but commit to stockroom along with you commit your source code In case you need, the source code for the above experiment is available at the github repository hhsecond/stockroom-cifar10","title":"Quick Start"},{"location":"quick-start/#quick-start","text":"Eager to start using stockroom? This page gives a good and crisp introduction to stockroom. Import a cifar10 dataset from torchvision to stockroom Train a CNN with this data Save the hyper parameters and model to stockroom for reproducibility You need to install stockroom , pytorch , torchvision and matplotlib for this tutorial Use conda installing pytorch and torchvision using pypi might install the manylinux bundle which is huge in size. Use conda if you can","title":"\ud83c\udfc3\u200d\u2640\ufe0f Quick Start"},{"location":"quick-start/#introduction","text":"Stockroom exposes the data as three shelves. Data, Model and Experiments. This segregation let stockroom to be prejudice about what goes inside and optimize the storage. Stockroom also introduces stock CLI which gives you the ability to interact with your stockroom repository in a git-like way. Checkout the reference doc for complete CLI reference. You'll be using both the CLI and Python APIs of stockroom in this tutorial.","title":"Introduction"},{"location":"quick-start/#initialize-stock-repository","text":"CD to your project directory and initialize it as a stock repository $ stock init --username myname --email a@b.c ---> 100%","title":"Initialize Stock Repository"},{"location":"quick-start/#import-cifar10","text":"StockRoom keeps all your data in .data shelf arranged as columns. In our case, data is imported as four columns. Train images Train labels Test images Test labels Data is Tensor Stockroom makes strong assumptions about your data. Any data point that goes into stockroom must be a tensor a.k.a numpy.ndarray object. It is why stockroom could optimize the data storage and versioning efficiently. Also, know that, we have borrowed this philosophy from Hangar $ stock import torchvision.cifar10 Downloading cifar-10-python.tar.gz ---> 100% Adding cifar10 dataset to StockRoom ---> 100% Done! Once you have the CIFAR data downloaded and added to your stock repository, you can create your project files and start building the network. We are using the CIFAR10 example from pytorch's blitz tutorial here, with few modification to load the data from stockroom instead of torchvision. Stockroom is better off with git Stockroom is designed to be able work without git but git will enable you to track your source code along with machine learning artifacts and data","title":"Import CIFAR10"},{"location":"quick-start/#build-the-model","text":"We'll build a simple CNN model as given in the pytorch tutorial import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x","title":"Build The Model"},{"location":"quick-start/#exploring-data","text":"Stockroom gives you simple, dictionary-like APIs for accessing and storing things. You'd create a stock object that gives you the access to the storage from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Read Access Making stock object as given above will only give you a read enabled object. For saving data, you'd need to make a write enabled object using stock = StockRoom ( write = True ) You'll see an example below","title":"Exploring data"},{"location":"quick-start/#accessing-data","text":"As you already know, data is stored as columns inside the .data shelf in stockroom. You can get fetch the column from the .data attribute and then fetch the data at a particular index - here we take the 100th data point. from stockroom import StockRoom import matplotlib.pyplot as plt import numpy as np def imshow ( img ): plt . imshow ( np . transpose ( img , ( 1 , 2 , 0 ))) plt . show () stock = StockRoom () index = 100 img = stock . data [ 'cifar10-train-image' ][ index ] imshow ( img ) Column Names You need to know the column names to interact with the data in the .data shelf. Use stock . data . keys ()","title":"Accessing data"},{"location":"quick-start/#dataloader","text":"Making a PyTorch DataLoader for your data is possible with the make_torch_dataset function. It takes columns as first argument in a python list/tuple and gives you the element from each column on a particular index Info make_torch_dataset is a Hangar function and stockroom only exposing it for convenience","title":"DataLoader"},{"location":"quick-start/#make-dataset","text":"from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 )","title":"Make Dataset"},{"location":"quick-start/#make-dataloader","text":"The dataset returned from make_torch_dataset is a subclass of torch.utils.data.Dataset and hence is understood by torch DataLoader . You could create the dataloader as you create with any dataset. Huge batch size, custom collate function, multiple threads - doesn't matter. Use it as you wish. Remember, you have made a read only stock object, you'd never corrupt your data with that. from stockroom import make_torch_dataset from torch.utils.data import DataLoader imgcol = stock . data [ 'cifar10-train-image' ] lblcol = stock . data [ 'cifar10-train-label' ] dset = make_torch_dataset ([ imgcol , lblcol ]) dloader = DataLoader ( dset , batch_size = 64 )","title":"Make DataLoader"},{"location":"quick-start/#training","text":"We'll open a write enabled stock object here since we need to store experiment information (hyper parameters, metrics, output, artifacts etc) and model to stockroom. Careful with the write access With more power comes more responsibility. Remember, you can write to your repository Your data is safe With the power of hangar, any data that is committed to stockroom is safe there. Even if you overwrite that data in a new commit, you can always time travel to previous commit and access your old data","title":"Training"},{"location":"quick-start/#store-hyper-parameters","text":"As .data shelf store your data, hyper-parameters and experiment artifacts must be stored in the .experiment shelf. While the .data shelf only allow you to store tensor data, .experiment shelf will eventually allow you to store any artificats, like a loss graph, or a pickled file you'd need for training your model etc. stock = StockRoom ( write = True ) for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () stock . commit ( f \"Experiment with better result. Loss= { best_loss } \" ) best_loss = current_loss","title":"Store hyper-parameters"},{"location":"quick-start/#store-model","text":"The .model shelf takes state_dict from a pytorch model and nothing else. You will eventually be able to store a jit ed model into your .experiment store but .model shelf is designed to store your model weights passed as a dictionary. stock = StockRoom ( write = True ) for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () stock . commit ( f \"Experiment with better result. Loss= { best_loss } \" ) best_loss = current_loss Storing weights is better As far as you version your source code, saving the weights is always better. We are building more utilities, especially visualization tools, to interact with the data in stockroom. This will eventually help you to analyze the model weights, visualize them and even diff it \ud83e\udd2f\ud83d\ude0d","title":"Store model"},{"location":"quick-start/#commit-your-changes","text":"Commit your changes as you move forward, you can always time travel back and look at .data or .experiment or .model shelves stock = StockRoom ( write = True ) for epoch in range ( 2 ): p = tqdm ( dloader ) for i , ( inputs , labels ) in enumerate ( p ): optimizer . zero_grad () outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () running_loss += loss . item () if i % check_every == check_every - 1 : current_loss = running_loss / check_every running_loss = 0.0 if current_loss < best_loss : stock . experiment [ 'lr' ] = lr stock . experiment [ 'momentum' ] = momentum stock . model [ 'cifarmodel' ] = net . state_dict () stock . commit ( f \"Experiment with better result. Loss= { best_loss } \" ) best_loss = current_loss stock commit != git commit Stock commit is not same as a git commit. In fact, you can combine multiple stock commit in one git commit and consider that as an experiment","title":"Commit your changes"},{"location":"quick-start/#recap","text":"Initialize stock repository Import torchvision dataset to the repository Build the network Train your network Add data, augment it, experiment with hyper parameters but commit to stockroom along with you commit your source code In case you need, the source code for the above experiment is available at the github repository hhsecond/stockroom-cifar10","title":"Recap"}]}